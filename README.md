# The RBI Agile Engineering Maturity Model (AEMM)

Even if teams have a good understanding about their problem space, experience shows that many of them still need some ideas where to start improvements related to engineering practices. 

For this purpose, the team of Engineering Coaches here at RBI Head Office has created the Agile Engineering Maturity Review.
This review is done based on a simple questionnaire that describes engineering capabilities in the areas of CI/CD, DevOps, Test and Test Automation in various degrees of maturity. 
In a joint session, the team selects the answer that describes their current way of working best und thus puts itself into a maturity bucket.
  
It is strictly a self-evaluation process by the team, the framework just provides some guidance and structure and assuring that all of the relevant areas are covered.
This review process gives a baseline, it helps the teams to create common understanding about their way of working, and it also helps to figure out where to start any improvement activities.
The self assessment is in no way calibrated. 

**This means that it can't be used to compare and rank teams**. 

This is a futile exercise and besides this, will immediately make sure that teams won't feel safe to answer honestly!
 
 It is also important that the AEMM is just one tool to help teams improve. It can start conversations around important engineering topics but this is obviously not sufficient for any improvement.

Change is not happening linearly and there is no single path. 
Team context, business needs and boundary conditions all need to be observed - and as always, the most important thing is to start with *something*, collect feedback, and start all over!

Improvement is always possible - considering this it is clear that there is no end-state of an improvement journey. Even if a team scores itself top on all dimensions of the review it doesn't mean that it has achieved an optimal state of engineering capabilities. This state is simply not existing.

Conversations must be focused on capabilities and not on maturity scores if change should happen.

# How it is done
- The self assessment done by the teams together with Engineering Coaches that guide them through the questionnaire. 
- If it is the first iteration, Engineering Coaches are explaining the context
  - What is the assessment all about?
  - How does it work?
  - What happens with the data? Discussing this explicitly is very important.

- Coaches walk the team through the descriptions and for each topic, the team selects the description that fits to their ways of working best
- Descriptions and the respective buckets are classified as **Crawl, Walk and Run**.
  - **Crawl** means that the team is using a structured process 
  - **Walk** means that they are familiar with modern software engineering practices and are applying them in their daily work
  - **Run** means that the team is on top of their game and in addition they are also sharing their knowledge and experience and help the whole organization to improve
- If even the **Crawl** bucket description doesn't reflect the team's way of working, a **-** is used.
- Comments can be added by a coach for each topic if the team feels the necessity

It is helpful if two coaches work with the team on the self-assessment as it is hard to facilitate the process and take notes at the same time!

# How long does it take?
The duration of the self assessment depend on multiple variables:
- How many team members are involved in the assessment?
- How much time is used for discussion?
- How good is the team's joint understanding of the way of working?
- How familiar and experienced are the coaches with the process and the content of the questionnaire?

All in, we typically plan for 2 hours for the first assessment. 
For a bigger team this is certainly on the lower end and does not give a lot of time for discussion. 
Subsequent assessments are typically faster, it is also possible to skip discussions about specific topics in that case.

# What to do after the self-assessment?
- The heatmap generated by the Excel sheet is showing an overview immediately
- In RBI's case, Engineering Coaches do a short recap meeting (30 minutes) and prepare a set of improvement recommendations (usually five)
- Another 30 minutes meeting is scheduled with the team where coaches explain the recommendations and also collect feedback about the process
- It is up to the team to decide if they follow up on the recommendations


# What are our experiences?
- It is super important to explain to teams the context of the self assessment. The teams need to understand that this is not an *audit*, but it is for them.
- Teams also usually have a lot of questions what will happen with the results. It is again very important to emphasize that the data is only available to the teams and not to management. 
- Psychological safety is key. If teams feel uncomfortable the whole process is really unpleasant and stressful. Team members will get defensive quickly.
- The questionnaire is not perfect but is a very useful tool to stimulate discussion. We have experienced sessions where it became clear to the team that they don't even have a common understanding about their own way of working. This can be eye-opening!
- Teams early on the journey and with less exposure to topics like DevOps/CI/CD are often quite interested and appreciate some guidance. Some are not.
- It is really hard to separate the technical topics from general agility topics.
- It is up to the team to decide what their goals are. Not all teams need Spotify-like engineering muscle - or at least not immediately.
- With teams that are open and confident and feel safe a great and very useful conversation can emerge that is a brilliant learning experience for all people involved, including coaches.
- A lot of good conversation can happen if the whole team is doing the assessment together. But it will take a lot of time. It is difficult to steer the meeting in this case. Sometimes it may be better to streamline a bit and limit the number of people. We had good meetings with one developer and one tester knowledgeable about the team's way of working.
- It is good practice to follow up with the teams regularly and discuss any activities they might have started or any experiments they might have done. This may also provide a lot of useful insights about potential underlying problems that keep teams from improving on engineering side.


# Useful hints
- Two coaches in the review meeting are good practice. Facilitating and note-taking at the same time doesn't work.
- Try to keep the pace. If the review meeting takes too long it is hard to keep focus.
- Every single line in the sheet could be discussed for hours. This is not rocket science and high precision is not the goal.
- The self assessment must be done with engineers. Don't include Product Owners or Engineering Managers. You want to have the engineers talking, not the POs (or Scrum Masters). POs tend to talk a lot :-D.
- If agile coaches are working with the team, get in touch with them. There is always a lot of overlap!
